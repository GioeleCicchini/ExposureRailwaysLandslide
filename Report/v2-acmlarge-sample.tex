% v2-acmlarge-sample.tex, dated March 6 2012
% This is a sample file for ACM large trim journals
%
% Compilation using 'acmlarge.cls' - version 1.3, Aptara Inc.
% (c) 2011 Association for Computing Machinery (ACM)
%
% Questions/Suggestions/Feedback should be addressed to => "acmtexsupport@aptaracorp.com".
% Users can also go through the FAQs available on the journal's submission webpage.
%
% Steps to compile: latex, bibtex, latex latex
%
\documentclass[prodmode,acmtap]{acmlarge}

% Metadata Information
%\acmVolume{2}
%\acmNumber{3}
\acmArticle{1}
%\articleSeq{1}
\acmYear{2017}
\acmMonth{5}

% Package to generate and customize Algorithm as per ACM style
\usepackage[ruled]{algorithm2e}
\SetAlFnt{\algofont}
\SetAlCapFnt{\algofont}
\SetAlCapNameFnt{\algofont}
\SetAlCapHSkip{0pt}
\IncMargin{-\parindent}
\renewcommand{\algorithmcfname}{ALGORITHM}

% Page heads
\markboth{G. Cicchini, M. Polsinelli and A. Torretti}{Algoritmo per il calcolo dell’esposizione al rischio di frane applicato alle stazioni e linee ferroviarie abruzzesi}

% Title portion
\title{Algoritmo per il calcolo dell’esposizione al rischio di frane applicato alle stazioni e linee ferroviarie abruzzesi}
\author{Gioele Cicchini, Matteo Polsinelli, Anthony Torretty \affil{University of L'Aquila}
}
% NOTE! Affiliations placed here should be for the institution where the
%       BULK of the research was done. If the author has gone to a new
%       institution, before publication, the (above) affiliation should NOT be changed.
%       The authors 'current' address may be given in the "Author's addresses:" block (below).
%       So for example, Mr. Fogarty, the bulk of the research was done at UIUC, and he is
%       currently affiliated with NASA.

\begin{abstract}
Lorem ipsum dolor sit amet, consectetur adipiscing elit. In ac faucibus magna, eu tristique leo. Cras et dignissim ex, et vehicula tellus. Nullam nisl felis, sagittis a posuere vel, ultricies vitae nulla. Suspendisse potenti. In non vestibulum odio. Fusce fringilla molestie ante. Suspendisse convallis quam non ipsum accumsan sollicitudin. Nullam bibendum laoreet nunc, ut blandit leo tempus at. Praesent rhoncus ante eu nunc fringilla, egestas luctus nibh fringilla. Donec at porta urna. Duis vitae rhoncus libero. Praesent eget venenatis sapien, at placerat neque. Nulla nec sem euismod, imperdiet sapien non, malesuada magna. Nulla et nisi quam. Ut diam turpis, tristique id neque sed, consectetur egestas nibh.
Suspendisse potenti. Morbi elit ex, ornare at enim in, hendrerit tempor enim. Fusce sed leo odio. Vestibulum fermentum erat non mauris semper lacinia. Nullam et quam ut mi mattis tempus. Aenean dapibus, augue vel mattis cursus, nulla lorem eleifend libero, ac maximus nisl risus non felis. Fusce sed justo id arcu dapibus porta. Proin iaculis id libero id tempus. Nulla at urna id nunc fermentum efficitur et ornare erat. Aenean a arcu nec magna rutrum placerat nec a lectus. Nam malesuada libero interdum leo semper egestas.
\end{abstract}

\category{H.5.2}{Information Interfaces and Presentation}{User
Interfaces}[Evaluation/\break methodology]
\category{H.1.2}{Models and Principles}{User/Machine Systems}[Human Information Processing]
\category{I.5.1}{Patternbreak Recognition}{Models}[Neural Nets]

\terms{Human Factors}
\keywords{Contour perception, flow visualization, perceptual theory, visual cortex, visualization}

\acmformat{Daniel Pineo, Colin Ware, and Sean Fogarty. 2010. Neural Modeling of Flow Rendering Effectiveness.}
% At a minimum you need to supply the author names, year and a title.
% IMPORTANT:
% Full first names whenever they are known, surname last, followed by a period.
% In the case of two authors, 'and' is placed between them.
% In the case of three or more authors, the serial comma is used, that is, all author names
% except the last one but including the penultimate author's name are followed by a comma,
% and then 'and' is placed before the final author's name.
% If only first and middle initials are known, then each initial
% is followed by a period and they are separated by a space.
% The remaining information (journal title, volume, article number, date, etc.) is 'auto-generated'.

\begin{document}

\maketitle

% Head 1
\section{Introduction}
Il dissesto idrogeologico costituisce un tema di particolare rilevanza per l’Italia a causa degli impatti sulla popolazione, sulle infrastrutture lineari di comunicazione e sul tessuto economico e produttivo. L’Italia, per la sua conformazione geologica, geomorfologica e idrografica, è naturalmente predisposta ai fenomeni di dissesto. Tra gli eventi più catastrofici, dovuto al dissesto idrogeologico, troviamo le frane. Le frane sono fenomeni estremamente diffusi in Italia, anche tenuto conto che il 75\% del territorio nazionale è montano-collinare. Delle 700.000 frane contenute nelle banche dati dei paesi europei (JRC, 2012), oltre 500.000 sono censite nell’Inventario dei Fenomeni Franosi in Italia (Progetto IFFI). Circa un terzo del totale delle frane in Italia sono fenomeni a cinematismo rapido (crolli, colate rapide di fango e detrito), caratterizzati da velocità elevate, fino ad alcuni metri al secondo, e da elevata distruttività, spesso con gravi conseguenze in termini di perdita di vite umane \cite{trigila2015dissesto} . Anticipare i dissesti causati dai fenomeni naturali è in parte possibile con nuove tecnologie all’avanguardia che sono state oggetto di studio e ricerca per vari anni e che oggi sono diventate realtà mature ed applicabili. Investire nella prevenzione comporta un numero considerevole di vantaggi. Innanzitutto c’è un miglioramento della qualità della vita delle popolazioni che risiedono nelle zone ad alto rischio, le quali possono vivere la quotidianità senza preoccuparsi di eventi catastrofici futuri. Inoltre mettere in pratica la prevenzione implica un aumento dell’occupazione e mitiga considerevolmente i costi per il ripristino dei danni. La realizzazione di interventi mirati ed efficaci sul territorio presuppone la conoscenza, con un adeguato grado di confidenza, dei luoghi dove la probabilità di catastrofe sia significativa.


% Head 2
\subsection{The IBQ Approach in Image Quality Estimation}


% Table
\begin{table}[t]
\tbl{Multivariate Changes in Image Quality Attributes, the Relationship
of Psychometric and Objective Image Quality Estimations and the IBQ Approach}{%
\begin{tabular}{|l|p{8pc}|p{8pc}|p{12pc}|}
\hline
~PROBLEM   & \multicolumn{3}{l|}{{Estimating the performance when image
                                quality changes are multivariate}}\\\hline
{APPROACH} & {Objective measurements}    & \multicolumn{2}{|{c}|}{Subjective measurements}\\\cline{3-4}
           &                             & IBQ approach          & Psychometric approach\\\hline
GOAL       & Objective and computational
             measures for describing the
             changes in the images       & Definition of
                                           subjectively
                                           crucial image quality
                                           characteristics       & The amount of
                                                                   change in either
                                                                   the overall quality
                                                                   or a single attribute\\\hline
QUESTION   & What changes physically?    & What matters for the
                                           observer?             & How big is the perceived
                                                                   change?\\\hline
\end{tabular}}
\begin{tabnote}
The IBQ approach can help to determine the subjectively crucial
characteristics of an image and therefore to give weights to objective and
computational measures.
\end{tabnote}
\label{tab1}
\end{table}



% description
\begin{description}
    \item[Identify] Characteristics of an object.
    \item[Locate] Absolute or relative position.
    \item[Distinguish] Recognize as the same or different.
    \item[Categorize] Classify according to some property (e.g.,  color, position, or shape).
    \item[Cluster] Group same or related objects together.
    \item[Distribution] Describe the overall pattern.
    \item[Rank] Order objects of like types.
    \item[Compare] Evaluate different objects with each other.
    \item[Associate] Join in a relationship.
    \item[Correlate] A direct connection.
\end{description}

\subsection{Conditions}
The reproduction of the gestures was performed in the presence or
absence of visual and auditory feedback, resulting in four (2 $\times$ 2) conditions.
% enumerate
\begin{enumerate}
\item Visual and auditory feedback (V\,$+$\,A).
\item Visual feedback, no auditory feedback (V).
\item Auditory feedback, no visual feedback (A).
\item No visual or auditory feedback (None).
\end{enumerate}
The order of the four conditions was randomized across participants.
% itemize
\begin{itemize}
    \item \textit{when} $+$ \textit{where} $\Rightarrow$
          \textit{what}: State the properties of an object or objects at a
          certain ~time, or set of times,  and a certain place, or set of places.
    \item \textit{when} $+$ \textit{what} $\Rightarrow$
          \textit{where}: State the location or set of locations.
    \item \textit{where} $+$ \textit{what} $\Rightarrow$
          \textit{when}: State the time or set of times.
\end{itemize}
When conducting a user study, the goal for the study is to measure
the suitability of the visualization in some sense. What is actually
measured is a fundamental question that we believe can be handled by
using the concepts of {effectiveness}, {efficiency},
and {satisfaction}. These three concepts are derived from the
ISO standard of usability 9241-11.
% quote
\begin{quote}
    Extent to which a product can be used by specified users to
    achieve specified goals with \textit{effectiveness},
    \textit{efficiency}, and \textit{satisfaction} in a specified context of use.
\end{quote}

% Enunciations
\begin{theorem}
For a video sequence of $n$ frames, an optimal approach based on
dynamic programming can retrieve all levels of key frames together
with their temporal boundaries in O($n^4$) times.
\end{theorem}


% Figure
\begin{figure}[tp]
\centering
\includegraphics{acmlarge-mouse}
\caption{Neurons are arranged in V1 in a column architecture. Neurons
in a particular column respond preferentially to the same edge
orientation. Moving across the cortex (by a minute amount) yields
columns responding to edges having different orientations. A
hypercolumn is a section of cortex that represents a complete set of
orientations for a particular location in space.}
\label{corticalarchitecturefig}
\end{figure}

\section{Cortical Processing of Contours}

\begin{equation}
\label{gaboreqn}
Gabor(u,v,\lambda,\theta,\phi,\sigma,\gamma)=e^{-\frac{u'^{2}+
\gamma^{2}v'^{2}}{2\sigma^{2}}}cos(2\pi\frac{u'}{\lambda}+\phi).
\end{equation}



 (Figure~\ref{neuronalignmentfig}).

\begin{figure}[tp]
\centering
\includegraphics{acmlarge-mouse}
\caption{Neurons whose receptive fields are aligned along a
continuous contour mutually reinforce each other. They inhibit nearby
neurons with a similar orientation sensitivity.}
\label{neuronalignmentfig}
\end{figure}

\section{Li's V1 Model}
Based on the observed organization of the neurons in the visual
cortex by Hubel and Wiesel  and the
experimental evidence by , Zhaoping Li constructed a
simplified model of the behavior of V1 neurons and examined the
model's ability to integrate contours across multiple V1 neurons.
The model is introduced briefly here, and described in more detail in
. In Li's model, the cortex is approximated by a set
of hypercolumns arranged in a hexagonal grid. Each hexagonal cell has
12 orientation-selective neuron pairs oriented in 15-degree
increments. One of the main simplifications embodied in Li's model is
that it fails to incorporate the way the mammalian visual systems
scales with respect to the fovea. Real neural architectures have much
smaller receptive fields near the fovea at the center of vision than
at the edges of the visual field.
The neurons in each hex cell were grouped into excitatory and
inhibitory pairs responding to an edge of a particular orientation at
that location. Thus there were a total of 24 neurons per cell. The
firing rates of both the inhibitory and excitatory neurons were
modeled with real values. The neuron pairs affected neighboring
neuron pairs via a transfer function that depended on the alignment
of the edge selectivity orientations. Neuron pairs that were aligned
with one another exhibited an excitatory effect on each other, while
pairs that were not aligned inhibited each other. Finally, Li's model
also contains feedback pathways for higher-level visual areas to
influence individual neurons.

In our implementation, the mapping of the hexagonal grid to the image
space was such that the hex centers were separated by 10 pixels. For
the V1 neuron response, we used the Gabor function (Eq.
(\ref{gaboreqn})) with a wavelength, $\lambda$, of 21 pixels, a
$\sigma$ of 7 pixels, and an aspect ratio, $\gamma$, of 1.

\section{Streamline Tracing Algorithm}
 compared the effectiveness of
visualization techniques by presenting test subjects with the task of
estimating where a particle placed in the center of a flow field
would exit a circle. Six different flow-field visualization methods
were assessed by comparing the difference between the actual exit
numerically calculated and the estimation of the exit by the human
subjects. Laidlaw et~al.'s experiment was carried out on humans but,
in our work, we apply this evaluation technique to humans as well as
to our model of the human visual system and use a streamline tracing
algorithm to trace the path of the particle.

We use the term streamline tracing to describe the higher level
process that must exist for people to judge a streamline pathway.
We call it streamline tracing because the task seems to require the
user to make a series of judgments, starting at the center, whereby
the path of a particle dropped in the center is integrated in a
stepwise pattern to the edge of the field. Though many algorithms
exist in the machine vision literature for contour tracing, we found
these to be inappropriate for use in this application. Contour
tracing algorithms are generally designed to trace out the boundary
of some shape but a streamline tracing algorithm must also be able
able to produce a streamline in a field of disconnected contours,
such as is the case with the regular arrows. The streamline to be
traced will often not follow a visible contour but instead be locate
between contours, and will sometimes pass through areas devoid of
visual elements. Thus we developed a specialized algorithm that is
capable of tracing streamlines that do not necessarily correspond to
the boundary of any shape but can pass between visual contours.

Perception is a combination of top-down and bottom-up processes.
Bottom-up processes are driven by information on the retina and are
what is simulated by Li's model. Top-down
processes are much more varied and are driven in the brain by
activation from regions in the frontal and temporal cortex that are
known to be involved in the control of pattern identification and
attention . All of the flow visualizations evaluated
by , except for LIC, contain symbolic information
regarding the direction of flow along the contour elements (e.g. an
arrowhead). In a perpetual/cognitive process this would be regarded
as a top-down influence. At present our model does not deal with
symbolic direction information but it does do streamline tracing once
set in the right general direction.

Streamline tracing is a combination of top-down and bottom-up
processes. Broadly speaking, top-down processes reflect task demands
and the bottom-up processes reflect environmental information. In our
case, the bottom-up information comes from the different types of
visualization, while the top-down information is an attempt to model
the cognitive process of streamline pathway tracing. Contour
integration was modeled using the following iterative algorithm.

% Algorithm
\medskip
\begin{algorithm}[H]
\SetAlgoNoLine
$current\_position \leftarrow$ center \\
$current\_direction \leftarrow$ up \\
$current\_position$ is inside circle \\
\While{$current\_position$ is inside circle,}{
  $neighborhood \leftarrow$ all grid hexes within two hexes from $current\_position$ \\
  \For{ each $hex$ in $neighborhood$, }{
  \For{each $neuron$ in $hex$}{
  convert $neuron\_orientation$ to $vector$ \\
  scale $vector$ by $neuron\_excitation$ \\
  $vector\_sum \leftarrow vector\_sum + vector$}}

  normalize $vector\_sum$ \\
  $current\_position \leftarrow current\_position + vector\_sum$ \\
  $current\_direction \leftarrow vector\_sum$ \\
return $current\_position$ \\
}
    \caption{Iterative Algorithm}
    \label{alg:one}
  \end{algorithm}
\medskip

The algorithm maintains a context that contains a current position
and direction. Initially, the position is the center, and the
direction set to upward. This context models the higher-order,
top-down influence on the algorithm that results from the task
requirements (tracing from the center dot) and the directionality
which in our experiment was set to be always in an upwardly trending direction.

The algorithm traces the contour by repeatedly estimating the flow
direction at the $current\_position$ and moving the position a small
distance (.5 hex radii) in that direction. The flow direction is
calculated from the neural responses in the local neighborhood of the
$current\_position$. The excitation of each neuron is used to
generate a vector whose length is proportional to the strength of the
response and whose orientation is given by the receptive field
orientation. Because receptive field orientations are ambiguous as to
direction (for any vector aligned with the receptive field, its
negative is similarly aligned). The algorithm chose the vector most
closely corresponding to the vector computed on the previous
iteration. Vectors are computed for all neurons in hypercolumns
within a 2-hexes radius of the current position; they are summed and
normalized to generate the next $current\_direction$.

Some changes were made from the method published by
. Previously, the algorithm considered only a single
hex cell at each iteration of the algorithm. We found that this would
occasionally cause unrealistically large errors in streamline
tracing. For example, on visualizations with arrowheads, the neural
network might yield a very strong edge orthogonal to the flow field
positioned at the back of an arrowhead. If the algorithm considered
only the edges at this point, it may make a significant error,
despite the edges in nearby positions indicating the correct
direction. We felt that creating an average over $neighborhood$ was
the more correct approach, and we found closer agreement with human
performance with this change.

\subsection{Qualitative Evaluation}
Four different flow visualization methods were used in our evaluation
of the theory. These were implementations of four of the six used by
. We chose to investigate a regular arrow grid
because it is still the most commonly used in practice and a jittered
arrow grid because of the arguments that have been made that this
should improve perceptual aliasing problems . We added
Line Integral Convolution (LIC) because of its widespread advocation
by the visualization community  and head-to-tail
aligned streaklets because of Laidlaw et al.'s finding that is was
the best and the theoretical arguments in support of this method
. Note that Laidlaw et al. used Turk and Banks
algorithm to achieve aligned arrows on equally spaced streamlines
while we used Jobard and Lefer's  method to
achieve the same effect and we used streaklets without an arrowhead
.

\begin{figure}[tp]
    \begin{minipage}[t]{0.45\linewidth}
        \centering
        \includegraphics{acmlarge-mouse}
        \caption{Regular arrows.}
        \label{regularfig}
    \end{minipage}
    \hspace{0.1\linewidth}
    \begin{minipage}[t]{0.45\linewidth}
        \centering
        \includegraphics{acmlarge-mouse}
        \caption{Jittered arrows.}
        \label{jitteredfig}
    \end{minipage}
\end{figure}

\begin{figure}[tp]
    \begin{minipage}[t]{0.45\linewidth}
        \centering
        \includegraphics{acmlarge-mouse}
        \caption{Closeup of neural response to arrowheads.}
        \label{ortharrowheadfig}
    \end{minipage}
    \hspace{0.1\linewidth}
    \begin{minipage}[t]{0.45\linewidth}
        \centering
        \includegraphics{acmlarge-mouse}
        \caption{Closeup of neural response to aligned streaklets.}
        \label{alignedcloseupfig}
    \end{minipage}
\end{figure}


V1 is known to have detectors at different scales. However, to make
the problem computationally tractable we chose only a single scale
for the V1 and designed the data visualizations with elements scaled
such that they were effectively detected by the gabor filter used by
the model. The widths of the arrows and streaklets were chosen to be
smaller than the central excitatory band of the gabor filter. This
allowed the edge to be detected even if not precisely centered on the
receptive field of the neuron. The spatial frequency of the LIC
visualization is defined by the texture over which the vector field
is convoluted. Our texture was created by generating a texture of
random white noise of one-third the necessary size and scaling it up
via. interpolation. The resulting spacial frequency of the LIC
visualization was of a scale that was effectively detected by the
gabor filters of the model.

% Head 3
\subsubsection{Regular Arrows (Figure \ref{regularfig})} This
visualization is produced by placing arrow glyphs at regular
spacings. The magnitude of the vector field is indicated by the arrow
length, and the flow direction by the arrow head. The grid underlying
the regular arrows is apparent to humans, but the edge weights of the
model show no obvious signs of being negatively affected. In fact,
the regularity ensures that the arrows are well spaced, preventing
any false edge responses that might be produced by the interference
of multiple arrows. We can expect that nontangential edge responses
will be produced by the arrowheads and these will lead to errors in
the streamline advection task.

% Head 4
\paragraph{Jittered arrows (Figure \ref{jitteredfig})}
This visualization is similar to the regular arrows, but the arrows
are moved a small random distance from the regular locations. While
composed of the same basic elements as the regular grid, we see
instances where nearby arrows interfere with each other and produce
edge responses nontangential to the flow direction. Also, as with
gridded arrows, the arrowheads will excite neurons with orientation
selectivity nontangential to the flow. This can be seen in
Figure~\ref{ortharrowheadfig}. In this figure, we can see orthogonal
neural excitation to each side of the upper arrow, caused by the back
edge of the arrowhead (blue circles). We can also see excitation
caused by the interference of two arrows at the bottom right (green
circle). These nontangential responses are much stronger than those
found in the aligned streaklets visualization (Figure \ref{alignedcloseupfig}).


\section{Discussion}
The overall agreement between the pattern of results for human
observers and the V1-based model provides strong support of the
perceptual theory we outlined in the introduction. The aligned arrows
style of visualization produced clear chains of mutually reinforcing
neurons along the flow path in the representation, making the flow
pathway easy to trace as predicted by theory.

The fact that LIC produced results as good as the equally spaced
streamlines was something of a surprise, and this lends support to
its popularity within the visualization community. While it did not
produce as much neuron excitation as the aligned arrows method, this
was offset by the lack of nontangential edge responses produced by
glyph-based visualizations. However, its good performance was
achieved only because our evaluation method ignored the directional
ambiguity inherent in this method.  found this
method to be the worst and there is little doubt that had we allowed
flow in any direction, up or down, human observers would have found
pathways with close to 180 degrees of error half of the time.

The performance of both the model and the human test subjects is
likely to be highly dependent on the underlying vector field used.
As described in Section 5.1.6, the vector field was generated by
interpolating between an 8x8 grid of random, but generally upward
pointing vectors. A consequence of this is that when adjacent vectors
in this grid point somewhat toward each other, the vector field forms
an area of convergence. This convergence area tends to funnel
neighboring streamline paths together, reducing error in streamline
tracing (Figure \ref{regularfig} is an example of this).  Thus, the
overall accuracies of both the model and human subjects may be higher
than might be might be observed using a vector field without such convergence zones.

We were surprised that the computer algorithm actually did better at
the task than human observers. One reason for this may have been that
humans would have to make saccadic eye movements to trace a path,
whereas the computer did not. For the patterns we used, it is likely
that the observers had to make fixations on several successive parts
of a path, and errors may have accumulated as they resumed a trace
from a previous fixation. Nevertheless, we feel that the algorithm
could easily be adjusted to make it give results closer to human
subjects. A more sophisticated approach would be to simulate eye fixations.

The model we applied is a considerable simplification over what
actually occurs. It only uses the simplest model of the simplest
orientation sensitive neurons, and fails to include cortical
magnification, among other shortcomings. Real cortical receptive
fields are not arranged in a rigid hexagonal grid as they are in Li's
model. Furthermore, the neurons of V1 respond to many frequencies,
however our model only uses one in its present form. In addition,
besides the so-called simple cells modeled by , other
neurons in V1 and V2 called complex and hypercomplex cells all have
important functions. For example, end-stopped cell respond best to a
contour that terminates in the receptive field and understanding
these may be important in showing how the direction of flow along a
contour can be unambiguously shown. Moreover, visual information is
processed through several stages following the primary cortex,
including V2, V4 and the IT cortex. Each of these appears to abstract
more complex, less localized patterns. Researchers are far from
having sufficient information to model the operations of these stages
all of which may have a role in tracing contours. Nevertheless, the
results are compelling and there are advantages in having a
relatively simple model. We have plans to add some of these more
complex functions in future versions of the model.

% Start of "Sample References" section

\section{Typical references in new ACM Reference Format}


% Appendix
\appendix
\section*{APPENDIX}
\setcounter{section}{1}


With closest point to a given set of lines we intend the point
having the minimum Euclidean distance with respect to those lines.
Typically, this problem is formulated using Pl\"{u}cker coordinates.
Instead, here we compute this point by solving the problem in a closed
form, since the resulting matrices are not ill-conditioned in our
case. More precisely, by indicating the set of $n$ lines with
%
\begin{equation}
  L = \left \{ l_i = O_i + t \vec{d}_i | \, t \in {R} \right \} \,\,\, i = 1
  \ldots n,
  \label{eq:setoflines}
\end{equation}
%
where $O_i$ is the origin of the $i$th line and $\vec{d}_i$ is the
corresponding direction (normalized), we found the closest point by
minimizing
%
\begin{equation}
  p = \arg \min_{x} \sum_{i=1}^{n} d(x,l_i).
  \label{eq:problemstatement}
\end{equation}
%
The distance $d(x, l_i)$ can be written as
%
\begin{equation}
  d(x , l_i)^2 = (x - O_i) \left [ \textbf{I} - \vec{d_i} \vec{d_i}^T \right ] (x - O_i).
  \label{eq:distance}
\end{equation}
%
The minimization is obtained by substituting (\ref{eq:distance}) in
(\ref{eq:problemstatement}), and imposing the derivative to zero.
%
After some simple algebra, we obtain the final formulation:
%
\begin{equation}
  p = \left [ n \textbf{I} - \sum_{i=1}^{n} \vec{d_i} \vec{d_i}^T
  \right ]^{-1} \sum_{i=1}^{n} \left [ \textbf{I} - \vec{d_i} \vec{d_i}^T \right ] O_i.
  \label{eq:closedform}
\end{equation}

% Bibliography
\bibliographystyle{ACM-Reference-Format-Journals}
\bibliography{acmlarge-sample-bibfile}
                                % Sample .bib file with references that match those in
                                % the 'Specifications Document (V1.5)' as well containing
                                % 'legacy' bibs and bibs with 'alternate codings'.
                                % Gerry Murray - March 2012

% History dates
\received{February 2009}{July 2009}{October 2009}


\elecappendix


\section{Analysis of Invalid Trials}
\label{invalid}

\subsection{Results}


Invalid trials were previously defined as those trials in which the
subject pressed the space bar to end the trial without first bringing
the virtual finger to a stop. The number of invalid trials for each
subject is presented by feedback condition in Figure~12. Due to the
irregular distribution of the data, no significance test was run.
However, the figure shows two notable features. First, Subject 6 had
more invalid trials than any other subject. Second, more invalid
trials occurred under the proprioceptive-only (NV$+$P) feedback
condition than any other.



\subsection{Discussion}

Although the number of invalid trials is not directly related to task
performance, we now consider any trends that may be seen in this
information. No statistical tests were done with this data, but some
inferences can be drawn from the invalid trial counts in Figure 12.
The only obvious trend is that the NV$+$P condition appears to have
the most invalid trials, which is the case for all but two subjects.
In the post-experiment survey, one subject commented on this trend,
saying that with only proprioceptive motion feedback it was hard to
tell if the finger was moving or not. This might be a result of a
larger threshold for absolute motion detection for proprioceptive
feedback than for visual feedback. This difficulty in stopping the
finger did not appear to affect the ease of use ratings provided by
subjects, as no correlation was observed with invalid trial counts.

It is interesting to note that the no-feedback condition (NV$+$NP)
had fewer invalid trials than the proprioceptive-only condition
(NV$+$P), especially in light of the findings of Ghez et al. [1990]
that deafferented individuals tend to display endpoint drift in
non-sighted targeted reaching movements (equivalent to NV$+$NP
condition) while neurologically normal individuals do not (equivalent
to NV$+$P condition). A notable difference between our study and the
study by Ghez et al.\ is the availability of kinesthetic feedback
from the thumb pressing on the force sensor, which indicates the
magnitude of the applied force, that is, the movement command in our
study. Thus, under the no-feedback condition, subjects could use this
information to learn to apply grasping forces within the dead zone to
stop finger movement. When motion feedback is available, subjects are
likely focusing more on the feedback than on the forces applied,
since the feedback allows them to achieve better accuracy. Thus, at
the end of a trial, subjects are most likely using this feedback as
an indicator of zero velocity rather than attending to the applied
force. When visual feedback is available, it is easy to determine
whether the finger is moving or not; however, when only
proprioceptive feedback is available, the finger can be moving slowly
without the subject being aware of its motion. This explanation would
result in a larger number of failed trials for the NV$+$P condition
than for any other, as observed.

\end{document}
% End of v2-acmlarge-sample.tex (March 2012) - Gerry Murray, ACM
